{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19580a93-ea14-406c-8360-a6c372aa0df3",
   "metadata": {},
   "source": [
    "# LLMs Transfer Learning\n",
    "\n",
    "### perform sentiment analysis on the IMDb dataset using a pre-trained model from Hugging Face.\n",
    "\n",
    "Based on the documentation available at: https://huggingface.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c3fc7ab-f10c-4621-86d7-4c4560a550e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libriaries\n",
    "# pip install transformers datasets torch accelerate evaluate\n",
    "\n",
    "# Import necessary libriaries\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import load_dataset, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa453aa5-3643-443e-a465-ad00050d9bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7bb0410df1461982731ee438bf680a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Authenticate this Notebook to send the final model to the Hugging Face hub\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6713b942-c172-4dad-8ed6-703aa4e4d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Git Large File Storage (LFS)\n",
    "# !apt-get install git-lfs\n",
    "#pip install git-lfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71168bb7-7c58-464e-bda3-463b69841d42",
   "metadata": {},
   "source": [
    "## 1. Load the IMDb Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "924664b1-2719-4b4c-9e02-7beaffe12e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset('imdb')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db642e72-aff0-481d-94ab-a15d117873cf",
   "metadata": {},
   "source": [
    "## 2. Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb3deb2-3003-49ad-af94-286dda5ae73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess our messages\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    ## 1. Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    ## 2. Remove HTML tags\n",
    "    text = re.sub(\"<.*?>\",\" \", text)\n",
    "\n",
    "    ## 3. Replace contractions with full words\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "\n",
    "    # Delete newline characters\n",
    "    text = text.replace('\\n', ' ')\n",
    "    # Remove redundant spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f05dbbd-eebb-404b-ac7b-1a83d4c7c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement text cleaning\n",
    "\n",
    "data = data.map(lambda x: {'text': preprocess_text(x['text'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb46d48-f5e0-47a0-8ec0-b961587a04c4",
   "metadata": {},
   "source": [
    "## 3. Select a Pre-Trained Model from Hugging Face\n",
    "I choose `distilbert-base-uncased-finetuned-sst-2-english` pre-trained model for this project task, sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4ceafc-ba34-4fff-ad67-d7c1ae33e0c1",
   "metadata": {},
   "source": [
    "## 4. Apply Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "250f274d-a902-4b56-b650-0b22aef6564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model and tokenizer from Hugging Face\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706bccfe-54f0-4366-b45a-36d4457d028e",
   "metadata": {},
   "source": [
    "## 5. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acf1d26b-cd76-4d7e-9084-92f1ea92d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)    #, padding=\"max_length\"\n",
    "\n",
    "# Tokenize dataset\n",
    "tokenized_datasets = data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0775c246-5b12-438a-b638-4d2f6c100e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train_dataset into 80% to train and 20% to eval\n",
    "test_dataset = tokenized_datasets[\"test\"]\n",
    "train_dataset = tokenized_datasets[\"train\"].train_test_split(test_size=0.2)[\"train\"]\n",
    "eval_dataset = tokenized_datasets[\"train\"].train_test_split(test_size=0.2)[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd301b3-9d80-4b41-a288-2030af843299",
   "metadata": {},
   "source": [
    "## _________\n",
    "## 6. Enhancing Model Using Transfer Learning\n",
    "## Fine-tune pre-trained model on the project dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc2d4e-192c-48d0-8aa3-07883cd06dc4",
   "metadata": {},
   "source": [
    "### Define training arguments and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0886b85-8cf2-41db-87c4-b7e3e80dab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TrainingArguments\n",
    "repo_name = 'LLM_project'\n",
    "training_args = TrainingArguments(\n",
    "                        output_dir=repo_name,\n",
    "                        push_to_hub=True,\n",
    "                        evaluation_strategy=\"epoch\",\n",
    "                        save_strategy=\"epoch\",\n",
    "                        learning_rate=2e-5,\n",
    "                        per_device_train_batch_size=16,\n",
    "                        per_device_eval_batch_size=16,\n",
    "                        num_train_epochs=3,\n",
    "                        weight_decay=0.01,\n",
    "                        logging_steps=100,\n",
    "                        warmup_steps=100,\n",
    "                        load_best_model_at_end=True,                \n",
    ")\n",
    "\n",
    "# Create a batch of examples\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "\n",
    "\n",
    "# Load accuracy metric\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Generate evaluation function\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    output_labels, actual_labels = eval_pred\n",
    "    predictions = np.argmax(output_labels, axis=1)   #prediction is the highest output probability\n",
    "    return accuracy_metric.compute(predictions=predictions, references=actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e62474e1-16ff-44c7-ac12-1a9cd2403586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 15:48:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.120796</td>\n",
       "      <td>0.969600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.085196</td>\n",
       "      <td>0.980400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.104335</td>\n",
       "      <td>0.982200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3750, training_loss=0.08349320179621379, metrics={'train_runtime': 56948.2027, 'train_samples_per_second': 1.054, 'train_steps_per_second': 0.066, 'total_flos': 7829320013314560.0, 'train_loss': 0.08349320179621379, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Trainer\n",
    "trainer = Trainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=eval_dataset,\n",
    "                tokenizer=tokenizer,\n",
    "                data_collator=data_collator,\n",
    "                compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6b045f2-a250-402f-a6ac-e9fb95c175a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 26:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0851956456899643,\n",
       " 'eval_accuracy': 0.9804,\n",
       " 'eval_runtime': 1591.13,\n",
       " 'eval_samples_per_second': 3.142,\n",
       " 'eval_steps_per_second': 0.197,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate fine-tuned model\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d4312c-0647-4166-9ddc-beff3da5b628",
   "metadata": {},
   "source": [
    "## 7. Push the Model to Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cde4847a-0c29-4c8f-91fc-7c18ec366ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ThuyTran102/LLM_project/commit/fa6d719fc10e329bc3f8c7dd82e8932f38171bff', commit_message='End of training', commit_description='', oid='fa6d719fc10e329bc3f8c7dd82e8932f38171bff', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once we are happy with the results, push the model to the hub for later use and share with the NLP community\n",
    "# Push the Model to the Hugging Face Hub\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa93a9c1-9077-4b74-85d5-ca2b87ea92ec",
   "metadata": {},
   "source": [
    "## 8. Use fine-tuned model for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94779cda-e159-4931-9da7-444dca6688e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcbb94c8759467aa309161d3f2c800b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/847 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b485965cbf64988a77a8a874f481366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee31f72a7af64025b6f7361ca9542ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eaa68afcc534265a38306818bae1a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fc67ec42b140dba1ae8e44c2665ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb12157022b4d6699caf1fea3bd2a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the pipeline with the fine-tuned model\n",
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(model=\"ThuyTran102/LLM_project\")  # model_name = \"your-username/your-repo-name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3776a546-fa85-436d-8ef7-0ab132ae1d96",
   "metadata": {},
   "source": [
    "### Make Predictions on New Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99081e86-47a1-4eac-8376-de2eef38d985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997263550758362},\n",
       " {'label': 'NEGATIVE', 'score': 0.991361677646637},\n",
       " {'label': 'NEGATIVE', 'score': 0.9985843896865845},\n",
       " {'label': 'POSITIVE', 'score': 0.9988806843757629}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = [\"I loved this movie!\", \n",
    "            \"The movie was okay, but I wouldn't watch it again.\", \n",
    "            \"I didn't like the movie at all.\",\n",
    "            \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\"]\n",
    "\n",
    "# Get predictions\n",
    "predictions = sentiment_pipeline(new_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b791bb5-2916-4642-aff3-3b44e68c882a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I loved this movie!\n",
      "Predicted sentiment: POSITIVE, Confidence: 0.9997263550758362\n",
      "\n",
      "Text: The movie was okay, but I wouldn't watch it again.\n",
      "Predicted sentiment: NEGATIVE, Confidence: 0.991361677646637\n",
      "\n",
      "Text: I didn't like the movie at all.\n",
      "Predicted sentiment: NEGATIVE, Confidence: 0.9985843896865845\n",
      "\n",
      "Text: This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\n",
      "Predicted sentiment: POSITIVE, Confidence: 0.9988806843757629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display predictions\n",
    "for text, prediction in zip(new_data, predictions):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted sentiment: {prediction['label']}, Confidence: {prediction['score']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ffa971-5960-4922-9a8c-d2c257415bc0",
   "metadata": {},
   "source": [
    "### Make Predictions on small unseen Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "413ebf77-c040-4984-b573-46631333d989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9995478987693787},\n",
       " {'label': 'NEGATIVE', 'score': 0.9666439890861511},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997088313102722},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997569918632507},\n",
       " {'label': 'POSITIVE', 'score': 0.9985153079032898},\n",
       " {'label': 'NEGATIVE', 'score': 0.9993792772293091},\n",
       " {'label': 'NEGATIVE', 'score': 0.9825100302696228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9998304843902588},\n",
       " {'label': 'NEGATIVE', 'score': 0.9996961355209351},\n",
       " {'label': 'NEGATIVE', 'score': 0.9998137354850769}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test = data['test']['text'][:10]  # Let's take the first 10 reviews from the test set\n",
    "predictions = sentiment_pipeline(sample_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42ae16a5-17b8-43ca-b7de-0c23f7012f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: i love sci-fi and am willing to put up with a lot. sci-fi movies/tv are usually underfunded, under-appreciated and misunderstood. i tried to like this, i really did, but it is to good tv sci-fi as babylon 5 is to star trek (the original). silly prosthetics, cheap cardboard sets, stilted dialogues, cg that does not match the background, and painfully one-dimensional characters cannot be overcome with a isci-fi' setting. (i am sure there are those of you out there who think babylon 5 is good sci-fi tv. it is not. it is clichÃ©d and uninspiring.) while us viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. star trek). it may treat important issues, yet not as a serious philosophy. it is really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. their actions and reactions are wooden and predictable, often painful to watch. the makers of earth know it is rubbish as they have to always say \"gene roddenberry is earth...\" otherwise people would not continue watching. roddenberry is ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging trabant of a show lumbers into space. spoiler. so, kill off a main character. and then bring him back as another actor. jeeez! dallas all over again.\n",
      "Predicted sentiment: NEGATIVE, Confidence: 0.9995478987693787\n",
      "\n",
      "Text: worth the entertainment value of a rental, especially if you like action movies. this one features the usual car chases, fights with the great van damme kick style, shooting battles with the 40 shell load shotgun, and even terrorist style bombs. all of this is entertaining and competently handled but there is nothing that really blows you away if you have seen your share before. the plot is made interesting by the inclusion of a rabbit, which is clever but hardly profound. many of the characters are heavily stereotyped -- the angry veterans, the terrified illegal aliens, the crooked cops, the indifferent feds, the bitchy tough lady station head, the crooked politician, the fat federale who looks like he was typecast as the mexican in a hollywood movie from the 1940s. all passably acted but again nothing special. i thought the main villains were pretty well done and fairly well acted. by the end of the movie you certainly knew who the good guys were and were not. there was an emotional lift as the really bad ones got their just deserts. very simplistic, but then you were not expecting hamlet, right? the only thing i found really annoying was the constant cuts to vds daughter during the last fight scene. not bad. not good. passable 4.\n",
      "Predicted sentiment: NEGATIVE, Confidence: 0.9666439890861511\n",
      "\n",
      "Text: its a totally average film with a few semi-alright action sequences that make the plot seem a little better and remind the viewer of the classic van dam films. parts of the plot do not make sense and seem to be added in to use up time. the end plot is that of a very basic type that does not leave the viewer guessing and any twists are obvious from the beginning. the end scene with the flask backs do not make sense as they are added in and seem to have little relevance to the history of van dam is character. not really worth watching again, bit disappointed in the end production, even though it is apparent it was shot on a low budget certain shots and sections in the film are of poor directed quality\n",
      "Predicted sentiment: NEGATIVE, Confidence: 0.9997088313102722\n",
      "\n",
      "Text: star rating: ***** saturday night **** friday night *** friday morning ** sunday night * monday morning former new orleans homicide cop jack robideaux (jean claude van damme) is re-assigned to columbus, a small but violent town in mexico to help the police there with their efforts to stop a major heroin smuggling operation into their town. the culprits turn out to be ex-military, lead by former commander benjamin meyers (stephen lord, otherwise known as jase from east enders) who is using a special method he learned in afghanistan to fight off his opponents. but jack has a more personal reason for taking him down, that draws the two men into an explosive final showdown where only one will walk away alive. after until death, van damme appeared to be on a high, showing he could make the best straight to video films in the action market. while that was a far more drama oriented film, with the shepherd he has returned to the high-kicking, no brainer action that first made him famous and has sadly produced his worst film since derailed. it is nowhere near as bad as that film, but what i said still stands. a dull, predictable film, with very little in the way of any exciting action. what little there is mainly consists of some limp fight scenes, trying to look cool and trendy with some cheap slo-mo/sped up effects added to them that sadly instead make them look more desperate. being a mexican set film, director isaac florentine has tried to give the film a robert rodriguez/desperado sort of feel, but this only adds to the desperation. vd gives a particularly uninspired performance and given he is never been a robert de niro sort of actor, that can not be good. as the villain, lord should not expect to leave the beeb anytime soon. he gets little dialogue at the beginning as he struggles to muster an american accent but gets mysteriously better towards the end. all the supporting cast are equally bland, and do nothing to raise the films spirits at all. this is one shepherd that is strayed right from the flock. *\n",
      "Predicted sentiment: NEGATIVE, Confidence: 0.9997569918632507\n",
      "\n",
      "Text: first off let me say, if you have not enjoyed a van damme movie since bloodsport, you probably will not like this movie. most of these movies may not have the best plots or best actors but i enjoy these kinds of movies for what they are. this movie is much better than any of the movies the other action guys (segal and dolph) have thought about putting out the past few years. van damme is good in the movie, the movie is only worth watching to van damme fans. it is not as good as wake of death (which i highly recommend to anyone of likes van damme) or in hell but, in my opinion it is worth watching. it has the same type of feel to it as nowhere to run. good fun stuff!\n",
      "Predicted sentiment: POSITIVE, Confidence: 0.9985153079032898\n",
      "\n",
      "Text: i had high hopes for this one until they changed the name to 'the shepherd : border patrol, the lamest movie name ever, what was wrong with just 'the shepherd'. this is a by the numbers action flick that tips its hat at many classic van damme films. there is a nice bit of action in a bar which reminded me of hard target and universal soldier but directed with no intensity or flair which is a shame. there is one great line about 'being p*ss drunk and carrying a rabbit' and some ok action scenes let down by the cheapness of it all. a lot of the times the dialogue does not match the characters mouth and the stunt men fall down dead a split second before even being shot. the end fight is one of the better van damme fights except the director tries to go a bit too john woo and fails also introducing flashbacks which no one really cares about just gets in the way of the action which is the whole point of a van damme film. not good, not bad, just average generic action.\n",
      "Predicted sentiment: NEGATIVE, Confidence: 0.9993792772293091\n",
      "\n",
      "Text: isaac florentine has made some of the best western martial arts action movies ever produced. in particular us seals 2, cold harvest, special forces and undisputed 2 are all action classics. you can tell isaac has a real passion for the genre and his films are always eventful, creative and sharp affairs, with some of the best fight sequences an action fan could hope for. in particular he has found a muse with scott adkins, as talented an actor and action performer as you could hope for. this is borne out with special forces and undisputed 2, but unfortunately the shepherd just does not live up to their abilities. there is no doubt that jcvd looks better here fight-wise than he has done in years, especially in the fight he has (for pretty much no reason) in a prison cell, and in the final showdown with scott, but look in his eyes. jcvd seems to be dead inside. there is nothing in his eyes at all. it is like he just does not care about anything throughout the whole film. and this is the leading man. there are other dodgy aspects to the film, script-wise and visually, but the main problem is that you are utterly unable to empathise with the hero of the film. a genuine shame as i know we all wanted this film to be as special as it genuinely could have been. there are some good bits, mostly the action scenes themselves. this film had a terrific director and action choreographer, and an awesome opponent for jcvd to face down. this could have been the one to bring the veteran action star back up to scratch in the balls-out action movie stakes. sincerely a shame that this did not happen.\n",
      "Predicted sentiment: NEGATIVE, Confidence: 0.9825100302696228\n",
      "\n",
      "Text: it actually pains me to say it, but this movie was horrible on every level. the blame does not lie entirely with van damme as you can see he tried his best, but let is face it, he is almost fifty, how much more can you ask of him? i find it so hard to believe that the same people who put together undisputed 2; arguably the best (western) martial arts movie in years, created this. everything from the plot, to the dialog, to the editing, to the overall acting was just horribly put together and in many cases outright boring and nonsensical. scott adkins who is fight scenes seemed more like a demo reel, was also terribly underused and not even the main villain which is such a shame because 1) he is more than capable of playing that role and 2) the actual main villain was not only not intimidating at all but also quite annoying. again, not blaming van damme. i will always be a fan, but avoid this one.\n",
      "Predicted sentiment: NEGATIVE, Confidence: 0.9998304843902588\n",
      "\n",
      "Text: technically i'am a van damme fan, or i was. this movie is so bad that i hated myself for wasting those 90 minutes. do not let the name isaac florentine (undisputed ii) fool you, i had big hopes for this one, depending on what i saw in (undisputed ii), man.. was i wrong ??! all action fans wanted a big comeback for the classic action hero, but i guess we wont be able to see that soon, as our hero keep coming with those (going -to-a-border - far-away-town-and -kill -the-bad-guys- than-comeback- home) movies i mean for god is sake, we are in 2008, and they insist on doing those disappointing movies on every level. why ??!!! do your self a favor, skip it.. seriously.\n",
      "Predicted sentiment: NEGATIVE, Confidence: 0.9996961355209351\n",
      "\n",
      "Text: honestly awful film, bad editing, awful lighting, dire dialog and scrappy screenplay. the lighting at is so bad there is moments you can not even see what is going on, i even tried to playing with the contrast and brightness so i could see something but that did not help. they must have found the script in a bin, the character development is just as awful and while you hardly expect much from a jean-claude van damme film this one manages to hit an all time low. you can not even laugh at the cheesy'ness. the directing and editing are also terrible, the whole film follows an extremely tired routine and fails at every turn as it bumbles through the plot that is so weak it is just unreal. there is not a lot else to say other than it is really bad and nothing like jean-claude van damme is earlier work which you could enjoy. avoid like the plaque, frankly words fail me in condemning this \"film\".\n",
      "Predicted sentiment: NEGATIVE, Confidence: 0.9998137354850769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display predictions\n",
    "for text, prediction in zip(sample_test, predictions):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted sentiment: {prediction['label']}, Confidence: {prediction['score']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a170a-1b6b-4c92-90d5-d1373ac486a6",
   "metadata": {},
   "source": [
    "### Make Predictions on all unseen Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ff44a7d-26c8-47c4-a12b-e0cc8f68a97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of pre-trained model before fine-tuning: {'accuracy': 0.92848}\n"
     ]
    }
   ],
   "source": [
    "# Map predictions to numerical labels\n",
    "def map_predictions_to_labels(pred_outputs):\n",
    "    return [0 if pred['label'] == 'NEGATIVE' else 1 for pred in pred_outputs]\n",
    "\n",
    "# Get predictions\n",
    "pred_outputs = sentiment_pipeline(test_dataset['text'], truncation=True)\n",
    "# Convert predictions to numerical labels\n",
    "pred_labels = map_predictions_to_labels(pred_outputs)\n",
    "\n",
    "# Get actual_labels\n",
    "actual_labels = test_dataset['label']\n",
    "\n",
    "# Load accuracy metric\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "# Calculate accuracy on evaluation set\n",
    "accuracy_result = accuracy_metric.compute(predictions=pred_labels, references=actual_labels)\n",
    "print(f\"Accuracy of pre-trained model before fine-tuning: {accuracy_result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
